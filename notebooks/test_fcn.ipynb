{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "torch.set_default_device('cpu')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from transformers_simple.fcn import FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 1000\n",
    "in_size = 20\n",
    "out_size = 1\n",
    "hidden_size = 10\n",
    "num_layers = 3\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "log_interval = 4\n",
    "learning_rate = 1e-2\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FCN(input_size=in_size, output_size=out_size, hidden_size=hidden_size, num_layers=num_layers,\n",
    "         activation=torch.nn.LeakyReLU(0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(num_data, in_size)\n",
    "Y = np.sum(np.abs(X),axis=1,keepdims=True)\n",
    "\n",
    "Ns = int(0.5*num_data)\n",
    "\n",
    "Xtrain = X[:Ns]\n",
    "Ytrain = Y[:Ns]\n",
    "\n",
    "Xtest = X[Ns:]\n",
    "Ytest = Y[Ns:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = TensorDataset(torch.Tensor(Xtrain), torch.Tensor(Ytrain))\n",
    "data_test = TensorDataset(torch.Tensor(Xtest), torch.Tensor(Ytest))\n",
    "\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(data_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(net.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/500 (0%)]\tLoss: 273.278900\n",
      "Train Epoch: 0 [128/500 (25%)]\tLoss: 264.815643\n",
      "Train Epoch: 0 [256/500 (50%)]\tLoss: 272.349457\n",
      "Train Epoch: 0 [384/500 (75%)]\tLoss: 242.481644\n",
      "Train Epoch: 1 [0/500 (0%)]\tLoss: 258.062469\n",
      "Train Epoch: 1 [128/500 (25%)]\tLoss: 197.261185\n",
      "Train Epoch: 1 [256/500 (50%)]\tLoss: 141.962555\n",
      "Train Epoch: 1 [384/500 (75%)]\tLoss: 70.285187\n",
      "Train Epoch: 2 [0/500 (0%)]\tLoss: 21.130394\n",
      "Train Epoch: 2 [128/500 (25%)]\tLoss: 41.358585\n",
      "Train Epoch: 2 [256/500 (50%)]\tLoss: 10.237909\n",
      "Train Epoch: 2 [384/500 (75%)]\tLoss: 10.644999\n",
      "Train Epoch: 3 [0/500 (0%)]\tLoss: 15.006744\n",
      "Train Epoch: 3 [128/500 (25%)]\tLoss: 8.443383\n",
      "Train Epoch: 3 [256/500 (50%)]\tLoss: 5.774733\n",
      "Train Epoch: 3 [384/500 (75%)]\tLoss: 6.402349\n",
      "Train Epoch: 4 [0/500 (0%)]\tLoss: 5.670076\n",
      "Train Epoch: 4 [128/500 (25%)]\tLoss: 4.163104\n",
      "Train Epoch: 4 [256/500 (50%)]\tLoss: 5.415508\n",
      "Train Epoch: 4 [384/500 (75%)]\tLoss: 6.142177\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        opt.zero_grad()\n",
    "        output = net(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                e, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformers_simple]",
   "language": "python",
   "name": "conda-env-transformers_simple-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
